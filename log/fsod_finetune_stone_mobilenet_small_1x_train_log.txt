Command Line Args: Namespace(config_file='configs/fsod/finetune_mobilenet_small_1x.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[32m[04/07 11:00:38 detectron2]: [0mRank of current process: 0. World size: 1
[32m[04/07 11:00:39 detectron2]: [0mEnvironment info:
----------------------  --------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) [GCC 7.5.0]
numpy                   1.19.5
detectron2              0.5 @/home/lcheng/anaconda3/envs/fsod1/lib/python3.6/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1+cu101 @/home/lcheng/anaconda3/envs/fsod1/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  8.4.0
torchvision             0.8.2+cu101 @/home/lcheng/anaconda3/envs/fsod1/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220212
iopath                  0.1.8
cv2                     4.5.5
----------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[04/07 11:00:39 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/fsod/finetune_mobilenet_small_1x.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[32m[04/07 11:00:39 detectron2]: [0mContents of args.config_file=configs/fsod/finetune_mobilenet_small_1x.yaml:
_BASE_: "mobilenet_small_1x.yaml"
MODEL:
  WEIGHTS: "./output/fsod/mobilenet_small_1x/model_final.pth" 
  MASK_ON: False
  BACKBONE:
    FREEZE_AT: 5
DATASETS:
  TRAIN: ("coco_2017_train_stone",)
  TEST: ("coco_2017_val_stone",)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.001
  STEPS:  (2000, 3000) #(2000,3000)
  MAX_ITER:  3100  # 3100
  WARMUP_ITERS: 200
INPUT:
  FS:
    FEW_SHOT: False # True #False,fine-tune
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 9
  MIN_SIZE_TRAIN: (240, 272, 304, 336, 368, 400) #(440, 472, 504, 536, 568, 600)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 370 # 620 # 370
  MAX_SIZE_TEST: 1000 
OUTPUT_DIR: './output/fsod/finetune_dir/mobilenet_small_1x'


[32m[04/07 11:00:39 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_stone
  TRAIN:
  - coco_2017_train_stone
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_SHOT: 9
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 370
  MIN_SIZE_TRAIN:
  - 240
  - 272
  - 304
  - 336
  - 368
  - 400
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_mobilenetV3small_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 64
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/mobilenet_small_1x/model_final.pth
OUTPUT_DIR: ./output/fsod/finetune_dir/mobilenet_small_1x
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 30000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3100
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 2000
  - 3000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[32m[04/07 11:00:39 detectron2]: [0mFull config saved to ./output/fsod/finetune_dir/mobilenet_small_1x/config.yaml
[32m[04/07 11:00:39 d2.utils.env]: [0mUsing a generated random seed 41398093
[32m[04/07 11:00:42 d2.engine.defaults]: [0mModel:
FsodRCNN(
  (backbone): MobileNetV3(
    (features): Sequential(
      (0): ConvBNActivation(
        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (1): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): SqueezeExcitation(
            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ConvBNActivation(
            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (2): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): ConvBNActivation(
            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (3): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): ConvBNActivation(
            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (4): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (5): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (6): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (7): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (8): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (9): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (10): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (11): InvertedResidual(
        (block): Sequential(
          (0): ConvBNActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (1): ConvBNActivation(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
          (2): SqueezeExcitation(
            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          )
          (3): ConvBNActivation(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
      (12): ConvBNActivation(
        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (classifier): Sequential(
      (0): Linear(in_features=576, out_features=1024, bias=True)
      (1): Dropout(p=0.2, inplace=True)
      (2): Linear(in_features=1024, out_features=1000, bias=True)
    )
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(48, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(48, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=96, eps=1e-05)
        )
        (conv1): Conv2d(
          48, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=96, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=96, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=96, eps=1e-05)
        )
      )
    )
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=96, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=96, out_features=2, bias=True)
      (conv_cor): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=96, out_features=2, bias=True)
      (fc_1): Linear(in_features=192, out_features=96, bias=True)
      (fc_2): Linear(in_features=96, out_features=96, bias=True)
      (cls_score_fc): Linear(in_features=96, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[32m[04/07 11:00:42 d2.data.datasets.coco]: [0mLoaded 20 images in COCO format from datasets/coco/annotations/instances_train2017.json
[32m[04/07 11:00:42 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[04/07 11:00:42 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[04/07 11:00:42 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   | category   | #instances   |
|:----------:|:-------------|:-----------|:-------------|
|     1      | 243          | 2          | 166          |
|            |              |            |              |
|   total    | 409          |            |              |[0m
[32m[04/07 11:00:42 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[04/07 11:00:42 d2.data.common]: [0mSerialized dataset takes 0.03 MiB
[32m[04/07 11:00:42 fewx.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/07 11:00:42 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from ./output/fsod/mobilenet_small_1x/model_final.pth ...
[32m[04/07 11:00:42 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/07 11:00:45 d2.utils.events]: [0m eta: 0:06:32  iter: 19  total_loss: 1.776  loss_cls: 0.6524  loss_box_reg: 0.835  loss_rpn_cls: 0.2572  loss_rpn_loc: 0.03498  time: 0.1291  data_time: 0.0356  lr: 0.0001855  max_mem: 307M
[32m[04/07 11:00:48 d2.utils.events]: [0m eta: 0:06:29  iter: 39  total_loss: 1.748  loss_cls: 0.6499  loss_box_reg: 0.8289  loss_rpn_cls: 0.2371  loss_rpn_loc: 0.03138  time: 0.1286  data_time: 0.0112  lr: 0.0002755  max_mem: 307M
[32m[04/07 11:00:51 d2.utils.events]: [0m eta: 0:06:27  iter: 59  total_loss: 1.706  loss_cls: 0.6461  loss_box_reg: 0.8191  loss_rpn_cls: 0.244  loss_rpn_loc: 0.02994  time: 0.1291  data_time: 0.0108  lr: 0.0003655  max_mem: 308M
[32m[04/07 11:00:53 d2.utils.events]: [0m eta: 0:06:24  iter: 79  total_loss: 1.758  loss_cls: 0.6426  loss_box_reg: 0.8525  loss_rpn_cls: 0.2808  loss_rpn_loc: 0.03816  time: 0.1302  data_time: 0.0102  lr: 0.0004555  max_mem: 308M
[32m[04/07 11:00:56 d2.utils.events]: [0m eta: 0:06:22  iter: 99  total_loss: 1.75  loss_cls: 0.6402  loss_box_reg: 0.8342  loss_rpn_cls: 0.2413  loss_rpn_loc: 0.03339  time: 0.1301  data_time: 0.0109  lr: 0.0005455  max_mem: 308M
[32m[04/07 11:00:59 d2.utils.events]: [0m eta: 0:06:19  iter: 119  total_loss: 1.773  loss_cls: 0.6379  loss_box_reg: 0.8357  loss_rpn_cls: 0.2439  loss_rpn_loc: 0.03146  time: 0.1294  data_time: 0.0097  lr: 0.0006355  max_mem: 308M
[32m[04/07 11:01:01 d2.utils.events]: [0m eta: 0:06:15  iter: 139  total_loss: 1.737  loss_cls: 0.6367  loss_box_reg: 0.8333  loss_rpn_cls: 0.2274  loss_rpn_loc: 0.02582  time: 0.1292  data_time: 0.0099  lr: 0.0007255  max_mem: 308M
[32m[04/07 11:01:04 d2.utils.events]: [0m eta: 0:06:11  iter: 159  total_loss: 1.735  loss_cls: 0.6366  loss_box_reg: 0.8396  loss_rpn_cls: 0.2513  loss_rpn_loc: 0.02963  time: 0.1286  data_time: 0.0112  lr: 0.0008155  max_mem: 308M
[32m[04/07 11:01:06 d2.utils.events]: [0m eta: 0:06:09  iter: 179  total_loss: 1.758  loss_cls: 0.6369  loss_box_reg: 0.8505  loss_rpn_cls: 0.2469  loss_rpn_loc: 0.0297  time: 0.1284  data_time: 0.0106  lr: 0.0009055  max_mem: 308M
[32m[04/07 11:01:09 d2.utils.events]: [0m eta: 0:06:06  iter: 199  total_loss: 1.731  loss_cls: 0.636  loss_box_reg: 0.8361  loss_rpn_cls: 0.2467  loss_rpn_loc: 0.02671  time: 0.1281  data_time: 0.0103  lr: 0.0009955  max_mem: 308M
[32m[04/07 11:01:11 d2.utils.events]: [0m eta: 0:06:03  iter: 219  total_loss: 1.811  loss_cls: 0.6362  loss_box_reg: 0.8273  loss_rpn_cls: 0.2624  loss_rpn_loc: 0.03167  time: 0.1280  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:14 d2.utils.events]: [0m eta: 0:06:01  iter: 239  total_loss: 1.749  loss_cls: 0.6365  loss_box_reg: 0.8583  loss_rpn_cls: 0.244  loss_rpn_loc: 0.02796  time: 0.1279  data_time: 0.0098  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:17 d2.utils.events]: [0m eta: 0:05:58  iter: 259  total_loss: 1.766  loss_cls: 0.6363  loss_box_reg: 0.8666  loss_rpn_cls: 0.2347  loss_rpn_loc: 0.02593  time: 0.1278  data_time: 0.0103  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:19 d2.utils.events]: [0m eta: 0:05:55  iter: 279  total_loss: 1.784  loss_cls: 0.6363  loss_box_reg: 0.8787  loss_rpn_cls: 0.2336  loss_rpn_loc: 0.0268  time: 0.1278  data_time: 0.0116  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:22 d2.utils.events]: [0m eta: 0:05:52  iter: 299  total_loss: 1.727  loss_cls: 0.6368  loss_box_reg: 0.8494  loss_rpn_cls: 0.2299  loss_rpn_loc: 0.02475  time: 0.1276  data_time: 0.0115  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:24 d2.utils.events]: [0m eta: 0:05:50  iter: 319  total_loss: 1.763  loss_cls: 0.6358  loss_box_reg: 0.8469  loss_rpn_cls: 0.2343  loss_rpn_loc: 0.02533  time: 0.1278  data_time: 0.0110  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:27 d2.utils.events]: [0m eta: 0:05:48  iter: 339  total_loss: 1.794  loss_cls: 0.6359  loss_box_reg: 0.875  loss_rpn_cls: 0.2444  loss_rpn_loc: 0.02711  time: 0.1280  data_time: 0.0111  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:29 d2.utils.events]: [0m eta: 0:05:46  iter: 359  total_loss: 1.774  loss_cls: 0.6361  loss_box_reg: 0.8652  loss_rpn_cls: 0.244  loss_rpn_loc: 0.02728  time: 0.1278  data_time: 0.0095  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:32 d2.utils.events]: [0m eta: 0:05:42  iter: 379  total_loss: 1.758  loss_cls: 0.6363  loss_box_reg: 0.8865  loss_rpn_cls: 0.2259  loss_rpn_loc: 0.02595  time: 0.1275  data_time: 0.0096  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:35 d2.utils.events]: [0m eta: 0:05:41  iter: 399  total_loss: 1.737  loss_cls: 0.6361  loss_box_reg: 0.8657  loss_rpn_cls: 0.2185  loss_rpn_loc: 0.024  time: 0.1278  data_time: 0.0104  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:37 d2.utils.events]: [0m eta: 0:05:38  iter: 419  total_loss: 1.757  loss_cls: 0.6368  loss_box_reg: 0.8672  loss_rpn_cls: 0.2343  loss_rpn_loc: 0.0246  time: 0.1276  data_time: 0.0102  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:40 d2.utils.events]: [0m eta: 0:05:36  iter: 439  total_loss: 1.773  loss_cls: 0.6362  loss_box_reg: 0.874  loss_rpn_cls: 0.2172  loss_rpn_loc: 0.02337  time: 0.1277  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:42 d2.utils.events]: [0m eta: 0:05:33  iter: 459  total_loss: 1.758  loss_cls: 0.6363  loss_box_reg: 0.8657  loss_rpn_cls: 0.2253  loss_rpn_loc: 0.02498  time: 0.1278  data_time: 0.0117  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:45 d2.utils.events]: [0m eta: 0:05:31  iter: 479  total_loss: 1.739  loss_cls: 0.6366  loss_box_reg: 0.8885  loss_rpn_cls: 0.1978  loss_rpn_loc: 0.02165  time: 0.1279  data_time: 0.0103  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:48 d2.utils.events]: [0m eta: 0:05:29  iter: 499  total_loss: 1.768  loss_cls: 0.6359  loss_box_reg: 0.8806  loss_rpn_cls: 0.2219  loss_rpn_loc: 0.02585  time: 0.1279  data_time: 0.0099  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:50 d2.utils.events]: [0m eta: 0:05:26  iter: 519  total_loss: 1.76  loss_cls: 0.6363  loss_box_reg: 0.8727  loss_rpn_cls: 0.2118  loss_rpn_loc: 0.02329  time: 0.1279  data_time: 0.0103  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:53 d2.utils.events]: [0m eta: 0:05:23  iter: 539  total_loss: 1.741  loss_cls: 0.6364  loss_box_reg: 0.883  loss_rpn_cls: 0.2204  loss_rpn_loc: 0.02533  time: 0.1278  data_time: 0.0100  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:55 d2.utils.events]: [0m eta: 0:05:20  iter: 559  total_loss: 1.73  loss_cls: 0.6361  loss_box_reg: 0.8782  loss_rpn_cls: 0.2188  loss_rpn_loc: 0.02249  time: 0.1278  data_time: 0.0109  lr: 0.001  max_mem: 308M
[32m[04/07 11:01:58 d2.utils.events]: [0m eta: 0:05:18  iter: 579  total_loss: 1.751  loss_cls: 0.6358  loss_box_reg: 0.8656  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.0267  time: 0.1278  data_time: 0.0114  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:01 d2.utils.events]: [0m eta: 0:05:15  iter: 599  total_loss: 1.768  loss_cls: 0.6357  loss_box_reg: 0.8926  loss_rpn_cls: 0.2152  loss_rpn_loc: 0.02473  time: 0.1278  data_time: 0.0108  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:03 d2.utils.events]: [0m eta: 0:05:14  iter: 619  total_loss: 1.73  loss_cls: 0.6368  loss_box_reg: 0.8795  loss_rpn_cls: 0.2153  loss_rpn_loc: 0.02526  time: 0.1280  data_time: 0.0108  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:06 d2.utils.events]: [0m eta: 0:05:11  iter: 639  total_loss: 1.767  loss_cls: 0.6356  loss_box_reg: 0.8871  loss_rpn_cls: 0.212  loss_rpn_loc: 0.02413  time: 0.1279  data_time: 0.0101  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:08 d2.utils.events]: [0m eta: 0:05:07  iter: 659  total_loss: 1.746  loss_cls: 0.6359  loss_box_reg: 0.8776  loss_rpn_cls: 0.2049  loss_rpn_loc: 0.02521  time: 0.1277  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:11 d2.utils.events]: [0m eta: 0:05:05  iter: 679  total_loss: 1.75  loss_cls: 0.6358  loss_box_reg: 0.8788  loss_rpn_cls: 0.2  loss_rpn_loc: 0.02474  time: 0.1277  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:14 d2.utils.events]: [0m eta: 0:05:02  iter: 699  total_loss: 1.694  loss_cls: 0.6355  loss_box_reg: 0.8537  loss_rpn_cls: 0.1871  loss_rpn_loc: 0.02129  time: 0.1276  data_time: 0.0118  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:16 d2.utils.events]: [0m eta: 0:04:59  iter: 719  total_loss: 1.735  loss_cls: 0.6353  loss_box_reg: 0.859  loss_rpn_cls: 0.1981  loss_rpn_loc: 0.02229  time: 0.1276  data_time: 0.0118  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:19 d2.utils.events]: [0m eta: 0:04:57  iter: 739  total_loss: 1.741  loss_cls: 0.6369  loss_box_reg: 0.8894  loss_rpn_cls: 0.2135  loss_rpn_loc: 0.02487  time: 0.1275  data_time: 0.0100  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:21 d2.utils.events]: [0m eta: 0:04:54  iter: 759  total_loss: 1.782  loss_cls: 0.6353  loss_box_reg: 0.8854  loss_rpn_cls: 0.2155  loss_rpn_loc: 0.0279  time: 0.1276  data_time: 0.0127  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:24 d2.utils.events]: [0m eta: 0:04:52  iter: 779  total_loss: 1.807  loss_cls: 0.6354  loss_box_reg: 0.91  loss_rpn_cls: 0.2203  loss_rpn_loc: 0.02596  time: 0.1276  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:27 d2.utils.events]: [0m eta: 0:04:49  iter: 799  total_loss: 1.765  loss_cls: 0.6364  loss_box_reg: 0.8908  loss_rpn_cls: 0.2117  loss_rpn_loc: 0.0248  time: 0.1275  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:29 d2.utils.events]: [0m eta: 0:04:47  iter: 819  total_loss: 1.76  loss_cls: 0.634  loss_box_reg: 0.8856  loss_rpn_cls: 0.2104  loss_rpn_loc: 0.02468  time: 0.1275  data_time: 0.0119  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:32 d2.utils.events]: [0m eta: 0:04:44  iter: 839  total_loss: 1.747  loss_cls: 0.6354  loss_box_reg: 0.9046  loss_rpn_cls: 0.1881  loss_rpn_loc: 0.02073  time: 0.1275  data_time: 0.0108  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:34 d2.utils.events]: [0m eta: 0:04:41  iter: 859  total_loss: 1.741  loss_cls: 0.6354  loss_box_reg: 0.8872  loss_rpn_cls: 0.1847  loss_rpn_loc: 0.02204  time: 0.1274  data_time: 0.0111  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:37 d2.utils.events]: [0m eta: 0:04:39  iter: 879  total_loss: 1.737  loss_cls: 0.6353  loss_box_reg: 0.8929  loss_rpn_cls: 0.1917  loss_rpn_loc: 0.02353  time: 0.1273  data_time: 0.0108  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:39 d2.utils.events]: [0m eta: 0:04:36  iter: 899  total_loss: 1.759  loss_cls: 0.6342  loss_box_reg: 0.8959  loss_rpn_cls: 0.216  loss_rpn_loc: 0.02544  time: 0.1274  data_time: 0.0117  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:42 d2.utils.events]: [0m eta: 0:04:34  iter: 919  total_loss: 1.727  loss_cls: 0.6351  loss_box_reg: 0.8926  loss_rpn_cls: 0.2015  loss_rpn_loc: 0.02289  time: 0.1274  data_time: 0.0117  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:45 d2.utils.events]: [0m eta: 0:04:31  iter: 939  total_loss: 1.776  loss_cls: 0.6357  loss_box_reg: 0.921  loss_rpn_cls: 0.1848  loss_rpn_loc: 0.02185  time: 0.1274  data_time: 0.0114  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:47 d2.utils.events]: [0m eta: 0:04:29  iter: 959  total_loss: 1.774  loss_cls: 0.6353  loss_box_reg: 0.92  loss_rpn_cls: 0.197  loss_rpn_loc: 0.02373  time: 0.1275  data_time: 0.0116  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:50 d2.utils.events]: [0m eta: 0:04:26  iter: 979  total_loss: 1.723  loss_cls: 0.6354  loss_box_reg: 0.8697  loss_rpn_cls: 0.2003  loss_rpn_loc: 0.02445  time: 0.1275  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:53 d2.utils.events]: [0m eta: 0:04:24  iter: 999  total_loss: 1.757  loss_cls: 0.6348  loss_box_reg: 0.9074  loss_rpn_cls: 0.2089  loss_rpn_loc: 0.02615  time: 0.1275  data_time: 0.0118  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:55 d2.utils.events]: [0m eta: 0:04:21  iter: 1019  total_loss: 1.782  loss_cls: 0.6354  loss_box_reg: 0.8994  loss_rpn_cls: 0.215  loss_rpn_loc: 0.02614  time: 0.1276  data_time: 0.0129  lr: 0.001  max_mem: 308M
[32m[04/07 11:02:58 d2.utils.events]: [0m eta: 0:04:19  iter: 1039  total_loss: 1.731  loss_cls: 0.6344  loss_box_reg: 0.9039  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.02121  time: 0.1277  data_time: 0.0101  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:01 d2.utils.events]: [0m eta: 0:04:17  iter: 1059  total_loss: 1.749  loss_cls: 0.6349  loss_box_reg: 0.9087  loss_rpn_cls: 0.187  loss_rpn_loc: 0.02194  time: 0.1278  data_time: 0.0134  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:03 d2.utils.events]: [0m eta: 0:04:14  iter: 1079  total_loss: 1.747  loss_cls: 0.6351  loss_box_reg: 0.9006  loss_rpn_cls: 0.193  loss_rpn_loc: 0.02477  time: 0.1277  data_time: 0.0102  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:06 d2.utils.events]: [0m eta: 0:04:11  iter: 1099  total_loss: 1.773  loss_cls: 0.6339  loss_box_reg: 0.9187  loss_rpn_cls: 0.1793  loss_rpn_loc: 0.02267  time: 0.1277  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:08 d2.utils.events]: [0m eta: 0:04:09  iter: 1119  total_loss: 1.759  loss_cls: 0.6335  loss_box_reg: 0.8993  loss_rpn_cls: 0.1902  loss_rpn_loc: 0.02515  time: 0.1277  data_time: 0.0104  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:11 d2.utils.events]: [0m eta: 0:04:07  iter: 1139  total_loss: 1.783  loss_cls: 0.6339  loss_box_reg: 0.9098  loss_rpn_cls: 0.1907  loss_rpn_loc: 0.02197  time: 0.1277  data_time: 0.0115  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:14 d2.utils.events]: [0m eta: 0:04:04  iter: 1159  total_loss: 1.789  loss_cls: 0.6352  loss_box_reg: 0.9403  loss_rpn_cls: 0.2048  loss_rpn_loc: 0.02506  time: 0.1278  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:16 d2.utils.events]: [0m eta: 0:04:02  iter: 1179  total_loss: 1.755  loss_cls: 0.636  loss_box_reg: 0.9062  loss_rpn_cls: 0.187  loss_rpn_loc: 0.02402  time: 0.1278  data_time: 0.0108  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:19 d2.utils.events]: [0m eta: 0:03:59  iter: 1199  total_loss: 1.749  loss_cls: 0.635  loss_box_reg: 0.9154  loss_rpn_cls: 0.1944  loss_rpn_loc: 0.02359  time: 0.1278  data_time: 0.0104  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:21 d2.utils.events]: [0m eta: 0:03:57  iter: 1219  total_loss: 1.733  loss_cls: 0.6331  loss_box_reg: 0.9109  loss_rpn_cls: 0.1751  loss_rpn_loc: 0.02177  time: 0.1278  data_time: 0.0125  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:24 d2.utils.events]: [0m eta: 0:03:54  iter: 1239  total_loss: 1.721  loss_cls: 0.6322  loss_box_reg: 0.9123  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.0208  time: 0.1277  data_time: 0.0110  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:26 d2.utils.events]: [0m eta: 0:03:52  iter: 1259  total_loss: 1.741  loss_cls: 0.6339  loss_box_reg: 0.9151  loss_rpn_cls: 0.1793  loss_rpn_loc: 0.02113  time: 0.1277  data_time: 0.0101  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:29 d2.utils.events]: [0m eta: 0:03:49  iter: 1279  total_loss: 1.751  loss_cls: 0.6322  loss_box_reg: 0.9048  loss_rpn_cls: 0.1869  loss_rpn_loc: 0.02363  time: 0.1278  data_time: 0.0102  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:32 d2.utils.events]: [0m eta: 0:03:47  iter: 1299  total_loss: 1.75  loss_cls: 0.6318  loss_box_reg: 0.9094  loss_rpn_cls: 0.1899  loss_rpn_loc: 0.02546  time: 0.1279  data_time: 0.0103  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:35 d2.utils.events]: [0m eta: 0:03:45  iter: 1319  total_loss: 1.768  loss_cls: 0.6314  loss_box_reg: 0.9187  loss_rpn_cls: 0.177  loss_rpn_loc: 0.02323  time: 0.1279  data_time: 0.0102  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:37 d2.utils.events]: [0m eta: 0:03:42  iter: 1339  total_loss: 1.766  loss_cls: 0.6311  loss_box_reg: 0.9146  loss_rpn_cls: 0.1911  loss_rpn_loc: 0.02538  time: 0.1280  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:40 d2.utils.events]: [0m eta: 0:03:40  iter: 1359  total_loss: 1.772  loss_cls: 0.6303  loss_box_reg: 0.9094  loss_rpn_cls: 0.1975  loss_rpn_loc: 0.02746  time: 0.1281  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:43 d2.utils.events]: [0m eta: 0:03:37  iter: 1379  total_loss: 1.736  loss_cls: 0.632  loss_box_reg: 0.9177  loss_rpn_cls: 0.189  loss_rpn_loc: 0.02497  time: 0.1281  data_time: 0.0114  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:45 d2.utils.events]: [0m eta: 0:03:35  iter: 1399  total_loss: 1.737  loss_cls: 0.6331  loss_box_reg: 0.916  loss_rpn_cls: 0.1796  loss_rpn_loc: 0.02342  time: 0.1281  data_time: 0.0096  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:48 d2.utils.events]: [0m eta: 0:03:32  iter: 1419  total_loss: 1.765  loss_cls: 0.6328  loss_box_reg: 0.9188  loss_rpn_cls: 0.1959  loss_rpn_loc: 0.02336  time: 0.1281  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:50 d2.utils.events]: [0m eta: 0:03:30  iter: 1439  total_loss: 1.767  loss_cls: 0.6296  loss_box_reg: 0.9169  loss_rpn_cls: 0.1846  loss_rpn_loc: 0.0235  time: 0.1281  data_time: 0.0115  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:53 d2.utils.events]: [0m eta: 0:03:27  iter: 1459  total_loss: 1.764  loss_cls: 0.6292  loss_box_reg: 0.926  loss_rpn_cls: 0.1898  loss_rpn_loc: 0.02334  time: 0.1281  data_time: 0.0109  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:56 d2.utils.events]: [0m eta: 0:03:24  iter: 1479  total_loss: 1.74  loss_cls: 0.6305  loss_box_reg: 0.9092  loss_rpn_cls: 0.1894  loss_rpn_loc: 0.02421  time: 0.1281  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:03:58 d2.utils.events]: [0m eta: 0:03:22  iter: 1499  total_loss: 1.774  loss_cls: 0.6302  loss_box_reg: 0.9344  loss_rpn_cls: 0.1976  loss_rpn_loc: 0.02675  time: 0.1281  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:01 d2.utils.events]: [0m eta: 0:03:20  iter: 1519  total_loss: 1.749  loss_cls: 0.6302  loss_box_reg: 0.9236  loss_rpn_cls: 0.185  loss_rpn_loc: 0.02342  time: 0.1281  data_time: 0.0104  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:04 d2.utils.events]: [0m eta: 0:03:17  iter: 1539  total_loss: 1.728  loss_cls: 0.6336  loss_box_reg: 0.9215  loss_rpn_cls: 0.1677  loss_rpn_loc: 0.02147  time: 0.1282  data_time: 0.0100  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:06 d2.utils.events]: [0m eta: 0:03:15  iter: 1559  total_loss: 1.729  loss_cls: 0.6315  loss_box_reg: 0.9064  loss_rpn_cls: 0.1739  loss_rpn_loc: 0.0227  time: 0.1282  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:09 d2.utils.events]: [0m eta: 0:03:12  iter: 1579  total_loss: 1.731  loss_cls: 0.6252  loss_box_reg: 0.9104  loss_rpn_cls: 0.1773  loss_rpn_loc: 0.02413  time: 0.1282  data_time: 0.0110  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:11 d2.utils.events]: [0m eta: 0:03:10  iter: 1599  total_loss: 1.738  loss_cls: 0.6277  loss_box_reg: 0.9062  loss_rpn_cls: 0.1837  loss_rpn_loc: 0.02353  time: 0.1282  data_time: 0.0111  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:14 d2.utils.events]: [0m eta: 0:03:07  iter: 1619  total_loss: 1.749  loss_cls: 0.6281  loss_box_reg: 0.9124  loss_rpn_cls: 0.1772  loss_rpn_loc: 0.02244  time: 0.1282  data_time: 0.0127  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:17 d2.utils.events]: [0m eta: 0:03:04  iter: 1639  total_loss: 1.74  loss_cls: 0.633  loss_box_reg: 0.923  loss_rpn_cls: 0.1684  loss_rpn_loc: 0.02229  time: 0.1281  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:19 d2.utils.events]: [0m eta: 0:03:02  iter: 1659  total_loss: 1.752  loss_cls: 0.6409  loss_box_reg: 0.9299  loss_rpn_cls: 0.1801  loss_rpn_loc: 0.02348  time: 0.1282  data_time: 0.0124  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:22 d2.utils.events]: [0m eta: 0:03:00  iter: 1679  total_loss: 1.724  loss_cls: 0.6279  loss_box_reg: 0.9198  loss_rpn_cls: 0.1745  loss_rpn_loc: 0.02275  time: 0.1282  data_time: 0.0102  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:25 d2.utils.events]: [0m eta: 0:02:57  iter: 1699  total_loss: 1.757  loss_cls: 0.6282  loss_box_reg: 0.9137  loss_rpn_cls: 0.186  loss_rpn_loc: 0.0258  time: 0.1282  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:27 d2.utils.events]: [0m eta: 0:02:55  iter: 1719  total_loss: 1.723  loss_cls: 0.6235  loss_box_reg: 0.9001  loss_rpn_cls: 0.1851  loss_rpn_loc: 0.02387  time: 0.1282  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:30 d2.utils.events]: [0m eta: 0:02:52  iter: 1739  total_loss: 1.72  loss_cls: 0.6298  loss_box_reg: 0.9018  loss_rpn_cls: 0.1635  loss_rpn_loc: 0.02169  time: 0.1282  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:32 d2.utils.events]: [0m eta: 0:02:50  iter: 1759  total_loss: 1.751  loss_cls: 0.6281  loss_box_reg: 0.8924  loss_rpn_cls: 0.1802  loss_rpn_loc: 0.0249  time: 0.1282  data_time: 0.0111  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:35 d2.utils.events]: [0m eta: 0:02:47  iter: 1779  total_loss: 1.726  loss_cls: 0.6241  loss_box_reg: 0.9178  loss_rpn_cls: 0.1741  loss_rpn_loc: 0.02226  time: 0.1282  data_time: 0.0112  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:38 d2.utils.events]: [0m eta: 0:02:45  iter: 1799  total_loss: 1.754  loss_cls: 0.6288  loss_box_reg: 0.9045  loss_rpn_cls: 0.1641  loss_rpn_loc: 0.0213  time: 0.1282  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:40 d2.utils.events]: [0m eta: 0:02:42  iter: 1819  total_loss: 1.73  loss_cls: 0.6357  loss_box_reg: 0.9267  loss_rpn_cls: 0.1786  loss_rpn_loc: 0.0238  time: 0.1282  data_time: 0.0109  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:43 d2.utils.events]: [0m eta: 0:02:39  iter: 1839  total_loss: 1.755  loss_cls: 0.6219  loss_box_reg: 0.9224  loss_rpn_cls: 0.1675  loss_rpn_loc: 0.01939  time: 0.1282  data_time: 0.0105  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:45 d2.utils.events]: [0m eta: 0:02:37  iter: 1859  total_loss: 1.722  loss_cls: 0.6294  loss_box_reg: 0.9062  loss_rpn_cls: 0.1668  loss_rpn_loc: 0.02277  time: 0.1282  data_time: 0.0110  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:48 d2.utils.events]: [0m eta: 0:02:35  iter: 1879  total_loss: 1.75  loss_cls: 0.6238  loss_box_reg: 0.9237  loss_rpn_cls: 0.1782  loss_rpn_loc: 0.02312  time: 0.1283  data_time: 0.0103  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:51 d2.utils.events]: [0m eta: 0:02:32  iter: 1899  total_loss: 1.748  loss_cls: 0.624  loss_box_reg: 0.9132  loss_rpn_cls: 0.1767  loss_rpn_loc: 0.02362  time: 0.1284  data_time: 0.0109  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:54 d2.utils.events]: [0m eta: 0:02:30  iter: 1919  total_loss: 1.758  loss_cls: 0.6196  loss_box_reg: 0.9301  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.02335  time: 0.1284  data_time: 0.0122  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:56 d2.utils.events]: [0m eta: 0:02:27  iter: 1939  total_loss: 1.716  loss_cls: 0.6382  loss_box_reg: 0.9231  loss_rpn_cls: 0.1666  loss_rpn_loc: 0.01993  time: 0.1284  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:04:59 d2.utils.events]: [0m eta: 0:02:25  iter: 1959  total_loss: 1.761  loss_cls: 0.6331  loss_box_reg: 0.9319  loss_rpn_cls: 0.1785  loss_rpn_loc: 0.02546  time: 0.1285  data_time: 0.0110  lr: 0.001  max_mem: 308M
[32m[04/07 11:05:02 d2.utils.events]: [0m eta: 0:02:22  iter: 1979  total_loss: 1.735  loss_cls: 0.6292  loss_box_reg: 0.9047  loss_rpn_cls: 0.1821  loss_rpn_loc: 0.02408  time: 0.1285  data_time: 0.0107  lr: 0.001  max_mem: 308M
[32m[04/07 11:05:04 d2.utils.events]: [0m eta: 0:02:20  iter: 1999  total_loss: 1.725  loss_cls: 0.6158  loss_box_reg: 0.9103  loss_rpn_cls: 0.1608  loss_rpn_loc: 0.02011  time: 0.1284  data_time: 0.0106  lr: 0.001  max_mem: 308M
[32m[04/07 11:05:07 d2.utils.events]: [0m eta: 0:02:17  iter: 2019  total_loss: 1.698  loss_cls: 0.6127  loss_box_reg: 0.8991  loss_rpn_cls: 0.1562  loss_rpn_loc: 0.02105  time: 0.1284  data_time: 0.0105  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:09 d2.utils.events]: [0m eta: 0:02:15  iter: 2039  total_loss: 1.764  loss_cls: 0.6214  loss_box_reg: 0.9221  loss_rpn_cls: 0.1747  loss_rpn_loc: 0.02191  time: 0.1285  data_time: 0.0114  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:12 d2.utils.events]: [0m eta: 0:02:12  iter: 2059  total_loss: 1.731  loss_cls: 0.6163  loss_box_reg: 0.9345  loss_rpn_cls: 0.1728  loss_rpn_loc: 0.02297  time: 0.1285  data_time: 0.0105  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:15 d2.utils.events]: [0m eta: 0:02:09  iter: 2079  total_loss: 1.726  loss_cls: 0.6086  loss_box_reg: 0.901  loss_rpn_cls: 0.1835  loss_rpn_loc: 0.0263  time: 0.1285  data_time: 0.0109  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:17 d2.utils.events]: [0m eta: 0:02:07  iter: 2099  total_loss: 1.716  loss_cls: 0.6189  loss_box_reg: 0.9226  loss_rpn_cls: 0.1678  loss_rpn_loc: 0.02256  time: 0.1285  data_time: 0.0107  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:20 d2.utils.events]: [0m eta: 0:02:04  iter: 2119  total_loss: 1.727  loss_cls: 0.6166  loss_box_reg: 0.9114  loss_rpn_cls: 0.164  loss_rpn_loc: 0.0218  time: 0.1284  data_time: 0.0111  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:23 d2.utils.events]: [0m eta: 0:02:02  iter: 2139  total_loss: 1.736  loss_cls: 0.6209  loss_box_reg: 0.9109  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.02361  time: 0.1285  data_time: 0.0107  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:25 d2.utils.events]: [0m eta: 0:01:59  iter: 2159  total_loss: 1.728  loss_cls: 0.6139  loss_box_reg: 0.9347  loss_rpn_cls: 0.1871  loss_rpn_loc: 0.0249  time: 0.1285  data_time: 0.0114  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:28 d2.utils.events]: [0m eta: 0:01:56  iter: 2179  total_loss: 1.723  loss_cls: 0.6154  loss_box_reg: 0.9231  loss_rpn_cls: 0.1796  loss_rpn_loc: 0.0238  time: 0.1285  data_time: 0.0120  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:30 d2.utils.events]: [0m eta: 0:01:54  iter: 2199  total_loss: 1.748  loss_cls: 0.6146  loss_box_reg: 0.9249  loss_rpn_cls: 0.1783  loss_rpn_loc: 0.02326  time: 0.1285  data_time: 0.0111  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:33 d2.utils.events]: [0m eta: 0:01:51  iter: 2219  total_loss: 1.74  loss_cls: 0.6086  loss_box_reg: 0.931  loss_rpn_cls: 0.168  loss_rpn_loc: 0.02237  time: 0.1285  data_time: 0.0110  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:36 d2.utils.events]: [0m eta: 0:01:49  iter: 2239  total_loss: 1.737  loss_cls: 0.6217  loss_box_reg: 0.9302  loss_rpn_cls: 0.1625  loss_rpn_loc: 0.02289  time: 0.1284  data_time: 0.0116  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:38 d2.utils.events]: [0m eta: 0:01:47  iter: 2259  total_loss: 1.721  loss_cls: 0.6173  loss_box_reg: 0.9316  loss_rpn_cls: 0.165  loss_rpn_loc: 0.02221  time: 0.1285  data_time: 0.0105  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:41 d2.utils.events]: [0m eta: 0:01:44  iter: 2279  total_loss: 1.71  loss_cls: 0.6189  loss_box_reg: 0.9138  loss_rpn_cls: 0.1591  loss_rpn_loc: 0.02109  time: 0.1285  data_time: 0.0111  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:43 d2.utils.events]: [0m eta: 0:01:41  iter: 2299  total_loss: 1.734  loss_cls: 0.6132  loss_box_reg: 0.9254  loss_rpn_cls: 0.1656  loss_rpn_loc: 0.02145  time: 0.1285  data_time: 0.0097  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:46 d2.utils.events]: [0m eta: 0:01:39  iter: 2319  total_loss: 1.713  loss_cls: 0.6124  loss_box_reg: 0.9187  loss_rpn_cls: 0.1617  loss_rpn_loc: 0.02202  time: 0.1286  data_time: 0.0129  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:49 d2.utils.events]: [0m eta: 0:01:36  iter: 2339  total_loss: 1.707  loss_cls: 0.6133  loss_box_reg: 0.9291  loss_rpn_cls: 0.1582  loss_rpn_loc: 0.02305  time: 0.1286  data_time: 0.0115  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:52 d2.utils.events]: [0m eta: 0:01:34  iter: 2359  total_loss: 1.74  loss_cls: 0.6162  loss_box_reg: 0.9061  loss_rpn_cls: 0.1659  loss_rpn_loc: 0.02385  time: 0.1286  data_time: 0.0111  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:54 d2.utils.events]: [0m eta: 0:01:31  iter: 2379  total_loss: 1.723  loss_cls: 0.6197  loss_box_reg: 0.9376  loss_rpn_cls: 0.1688  loss_rpn_loc: 0.02415  time: 0.1286  data_time: 0.0127  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:57 d2.utils.events]: [0m eta: 0:01:29  iter: 2399  total_loss: 1.716  loss_cls: 0.6167  loss_box_reg: 0.9363  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.02128  time: 0.1286  data_time: 0.0112  lr: 0.0001  max_mem: 308M
[32m[04/07 11:05:59 d2.utils.events]: [0m eta: 0:01:26  iter: 2419  total_loss: 1.742  loss_cls: 0.6164  loss_box_reg: 0.9204  loss_rpn_cls: 0.1823  loss_rpn_loc: 0.02383  time: 0.1286  data_time: 0.0109  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:02 d2.utils.events]: [0m eta: 0:01:24  iter: 2439  total_loss: 1.722  loss_cls: 0.6181  loss_box_reg: 0.9228  loss_rpn_cls: 0.1677  loss_rpn_loc: 0.02313  time: 0.1286  data_time: 0.0117  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:05 d2.utils.events]: [0m eta: 0:01:21  iter: 2459  total_loss: 1.744  loss_cls: 0.6157  loss_box_reg: 0.9261  loss_rpn_cls: 0.1711  loss_rpn_loc: 0.0238  time: 0.1286  data_time: 0.0101  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:07 d2.utils.events]: [0m eta: 0:01:18  iter: 2479  total_loss: 1.71  loss_cls: 0.6138  loss_box_reg: 0.9149  loss_rpn_cls: 0.164  loss_rpn_loc: 0.02193  time: 0.1285  data_time: 0.0105  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:10 d2.utils.events]: [0m eta: 0:01:16  iter: 2499  total_loss: 1.758  loss_cls: 0.613  loss_box_reg: 0.9185  loss_rpn_cls: 0.1737  loss_rpn_loc: 0.02503  time: 0.1285  data_time: 0.0126  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:12 d2.utils.events]: [0m eta: 0:01:13  iter: 2519  total_loss: 1.701  loss_cls: 0.6153  loss_box_reg: 0.9176  loss_rpn_cls: 0.1575  loss_rpn_loc: 0.02172  time: 0.1286  data_time: 0.0111  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:15 d2.utils.events]: [0m eta: 0:01:11  iter: 2539  total_loss: 1.765  loss_cls: 0.6133  loss_box_reg: 0.9407  loss_rpn_cls: 0.1768  loss_rpn_loc: 0.02469  time: 0.1286  data_time: 0.0104  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:18 d2.utils.events]: [0m eta: 0:01:08  iter: 2559  total_loss: 1.753  loss_cls: 0.614  loss_box_reg: 0.9402  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.02256  time: 0.1286  data_time: 0.0113  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:20 d2.utils.events]: [0m eta: 0:01:06  iter: 2579  total_loss: 1.72  loss_cls: 0.6125  loss_box_reg: 0.9178  loss_rpn_cls: 0.1843  loss_rpn_loc: 0.02329  time: 0.1286  data_time: 0.0118  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:23 d2.utils.events]: [0m eta: 0:01:03  iter: 2599  total_loss: 1.751  loss_cls: 0.6129  loss_box_reg: 0.9259  loss_rpn_cls: 0.187  loss_rpn_loc: 0.0255  time: 0.1286  data_time: 0.0104  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:26 d2.utils.events]: [0m eta: 0:01:01  iter: 2619  total_loss: 1.716  loss_cls: 0.6077  loss_box_reg: 0.9314  loss_rpn_cls: 0.1712  loss_rpn_loc: 0.02442  time: 0.1286  data_time: 0.0114  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:28 d2.utils.events]: [0m eta: 0:00:58  iter: 2639  total_loss: 1.754  loss_cls: 0.6141  loss_box_reg: 0.9221  loss_rpn_cls: 0.1726  loss_rpn_loc: 0.02331  time: 0.1286  data_time: 0.0120  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:31 d2.utils.events]: [0m eta: 0:00:56  iter: 2659  total_loss: 1.717  loss_cls: 0.6196  loss_box_reg: 0.9167  loss_rpn_cls: 0.1639  loss_rpn_loc: 0.02306  time: 0.1286  data_time: 0.0106  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:34 d2.utils.events]: [0m eta: 0:00:53  iter: 2679  total_loss: 1.761  loss_cls: 0.6085  loss_box_reg: 0.952  loss_rpn_cls: 0.1905  loss_rpn_loc: 0.02525  time: 0.1287  data_time: 0.0122  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:36 d2.utils.events]: [0m eta: 0:00:51  iter: 2699  total_loss: 1.729  loss_cls: 0.608  loss_box_reg: 0.9041  loss_rpn_cls: 0.1656  loss_rpn_loc: 0.02241  time: 0.1287  data_time: 0.0101  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:39 d2.utils.events]: [0m eta: 0:00:48  iter: 2719  total_loss: 1.718  loss_cls: 0.6088  loss_box_reg: 0.9226  loss_rpn_cls: 0.1717  loss_rpn_loc: 0.02013  time: 0.1287  data_time: 0.0125  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:41 d2.utils.events]: [0m eta: 0:00:45  iter: 2739  total_loss: 1.725  loss_cls: 0.6152  loss_box_reg: 0.9306  loss_rpn_cls: 0.162  loss_rpn_loc: 0.0219  time: 0.1286  data_time: 0.0100  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:44 d2.utils.events]: [0m eta: 0:00:43  iter: 2759  total_loss: 1.716  loss_cls: 0.6095  loss_box_reg: 0.9264  loss_rpn_cls: 0.1737  loss_rpn_loc: 0.02402  time: 0.1286  data_time: 0.0113  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:47 d2.utils.events]: [0m eta: 0:00:40  iter: 2779  total_loss: 1.729  loss_cls: 0.6061  loss_box_reg: 0.9174  loss_rpn_cls: 0.1634  loss_rpn_loc: 0.02224  time: 0.1287  data_time: 0.0109  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:49 d2.utils.events]: [0m eta: 0:00:38  iter: 2799  total_loss: 1.726  loss_cls: 0.6114  loss_box_reg: 0.9279  loss_rpn_cls: 0.1664  loss_rpn_loc: 0.02241  time: 0.1287  data_time: 0.0106  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:52 d2.utils.events]: [0m eta: 0:00:35  iter: 2819  total_loss: 1.744  loss_cls: 0.5992  loss_box_reg: 0.9216  loss_rpn_cls: 0.188  loss_rpn_loc: 0.02602  time: 0.1287  data_time: 0.0105  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:55 d2.utils.events]: [0m eta: 0:00:33  iter: 2839  total_loss: 1.727  loss_cls: 0.6223  loss_box_reg: 0.8954  loss_rpn_cls: 0.1807  loss_rpn_loc: 0.02285  time: 0.1287  data_time: 0.0127  lr: 0.0001  max_mem: 308M
[32m[04/07 11:06:57 d2.utils.events]: [0m eta: 0:00:30  iter: 2859  total_loss: 1.74  loss_cls: 0.6098  loss_box_reg: 0.9155  loss_rpn_cls: 0.1745  loss_rpn_loc: 0.02247  time: 0.1287  data_time: 0.0118  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:00 d2.utils.events]: [0m eta: 0:00:28  iter: 2879  total_loss: 1.717  loss_cls: 0.6036  loss_box_reg: 0.9267  loss_rpn_cls: 0.1622  loss_rpn_loc: 0.02156  time: 0.1287  data_time: 0.0103  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:03 d2.utils.events]: [0m eta: 0:00:25  iter: 2899  total_loss: 1.698  loss_cls: 0.6173  loss_box_reg: 0.9251  loss_rpn_cls: 0.1586  loss_rpn_loc: 0.02133  time: 0.1287  data_time: 0.0129  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:05 d2.utils.events]: [0m eta: 0:00:23  iter: 2919  total_loss: 1.7  loss_cls: 0.6177  loss_box_reg: 0.9135  loss_rpn_cls: 0.1773  loss_rpn_loc: 0.02414  time: 0.1287  data_time: 0.0107  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:08 d2.utils.events]: [0m eta: 0:00:20  iter: 2939  total_loss: 1.752  loss_cls: 0.6186  loss_box_reg: 0.9354  loss_rpn_cls: 0.171  loss_rpn_loc: 0.02345  time: 0.1288  data_time: 0.0108  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:11 d2.utils.events]: [0m eta: 0:00:17  iter: 2959  total_loss: 1.696  loss_cls: 0.6071  loss_box_reg: 0.9048  loss_rpn_cls: 0.1705  loss_rpn_loc: 0.02178  time: 0.1287  data_time: 0.0112  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:13 d2.utils.events]: [0m eta: 0:00:15  iter: 2979  total_loss: 1.706  loss_cls: 0.6104  loss_box_reg: 0.9095  loss_rpn_cls: 0.1518  loss_rpn_loc: 0.02145  time: 0.1287  data_time: 0.0109  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:16 d2.utils.events]: [0m eta: 0:00:12  iter: 2999  total_loss: 1.744  loss_cls: 0.614  loss_box_reg: 0.9278  loss_rpn_cls: 0.1657  loss_rpn_loc: 0.02246  time: 0.1287  data_time: 0.0124  lr: 0.0001  max_mem: 308M
[32m[04/07 11:07:18 d2.utils.events]: [0m eta: 0:00:10  iter: 3019  total_loss: 1.719  loss_cls: 0.6166  loss_box_reg: 0.9127  loss_rpn_cls: 0.1706  loss_rpn_loc: 0.02354  time: 0.1288  data_time: 0.0125  lr: 1e-05  max_mem: 308M
[32m[04/07 11:07:21 d2.utils.events]: [0m eta: 0:00:07  iter: 3039  total_loss: 1.734  loss_cls: 0.6041  loss_box_reg: 0.9368  loss_rpn_cls: 0.1731  loss_rpn_loc: 0.02184  time: 0.1288  data_time: 0.0108  lr: 1e-05  max_mem: 308M
[32m[04/07 11:07:24 d2.utils.events]: [0m eta: 0:00:05  iter: 3059  total_loss: 1.699  loss_cls: 0.6078  loss_box_reg: 0.9165  loss_rpn_cls: 0.1522  loss_rpn_loc: 0.01903  time: 0.1288  data_time: 0.0103  lr: 1e-05  max_mem: 308M
[32m[04/07 11:07:27 d2.utils.events]: [0m eta: 0:00:02  iter: 3079  total_loss: 1.71  loss_cls: 0.6127  loss_box_reg: 0.8928  loss_rpn_cls: 0.1515  loss_rpn_loc: 0.02022  time: 0.1288  data_time: 0.0107  lr: 1e-05  max_mem: 308M
[32m[04/07 11:07:29 fvcore.common.checkpoint]: [0mSaving checkpoint to ./output/fsod/finetune_dir/mobilenet_small_1x/model_final.pth
[32m[04/07 11:07:29 d2.utils.events]: [0m eta: 0:00:00  iter: 3099  total_loss: 1.716  loss_cls: 0.6151  loss_box_reg: 0.9232  loss_rpn_cls: 0.1643  loss_rpn_loc: 0.02154  time: 0.1288  data_time: 0.0098  lr: 1e-05  max_mem: 308M
[32m[04/07 11:07:29 d2.engine.hooks]: [0mOverall training speed: 3098 iterations in 0:06:39 (0.1289 s / it)
[32m[04/07 11:07:29 d2.engine.hooks]: [0mTotal training time: 0:06:46 (0:00:07 on hooks)
[32m[04/07 11:07:29 d2.data.datasets.coco]: [0mLoaded 10 images in COCO format from datasets/coco/annotations/instances_val2017.json
[32m[04/07 11:07:29 d2.data.build]: [0mDistribution of instances among all 2 categories:
[36m|  category  | #instances   | category   | #instances   |
|:----------:|:-------------|:-----------|:-------------|
|     1      | 118          | 2          | 79           |
|            |              |            |              |
|   total    | 197          |            |              |[0m
[32m[04/07 11:07:29 d2.data.common]: [0mSerializing 10 elements to byte tensors and concatenating them all ...
[32m[04/07 11:07:29 d2.data.common]: [0mSerialized dataset takes 0.01 MiB
[32m[04/07 11:07:29 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(370, 370), max_size=1000, sample_style='choice')]
[32m[04/07 11:07:29 d2.evaluation.evaluator]: [0mStart inference on 10 batches
/home/lcheng/FewX-master/FewX-master/fewx/modeling/fsod/fsod_fast_rcnn.py:213: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
[32m[04/07 11:07:31 fewx.modeling.fsod.fsod_rcnn]: [0m=========== Offline support features are generated. ===========
[32m[04/07 11:07:31 fewx.modeling.fsod.fsod_rcnn]: [0m============ Few-shot object detetion will start. =============
